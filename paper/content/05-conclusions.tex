% !TEX root = ../main.tex
%
\chapter{Conclusions \& Future Work}
\label{sec:conclusions}

In this thesis, we explored the feasibility of LLM generation for synthetic online discussions. We created a custom framework supporting automated synthetic discussion, annotation and analysis, and explored two different prompting strategies; standard instruction prompting as well as framing the discussion as a competitive, scorable game. We then used this framework to generate three synthetic datasets, containing discussions, annotations by LLM annotators with different \acp{SDB}, and controversial comments respectively. 

In the context of this research, we used toxicity as a proxy for argument quality. Analyzing our synthetic dataset, we found that the presence of a moderator/facilitator can be a decisive influence on the toxicity of a discussion. Furthermore, framing the discussion as a scorable game seems to potentially keep LLM users in line using the threat of a moderator whose presence may not be perceivable. Finally, we defined a new statistical test that attributes polarization to specific \ac{SDB} features. Using this test alongside many other techniques we can not decisively prove that using different \acp{SDB} in LLM annotators yields any significant qualitative difference in their annotations. We also can't claim that any such difference could be attributed to the annotator reacting differently according to the content and context of the synthetic messages.

Future work should expand on making synthetic conversations more realistic, ideally rendering them indistinguishable from human online conversations. Additionally, there is room for experimentation involving scaling-up the number of \acp{SDB} and the information involved in them (age, education level, country of origin etc.). Furthermore, the \ac{SDF} enables the possibility of large-scale experiments exploring the effects of different moderation/facilitation techniques, interventions and LLM families on conversation quality. Finally, the findings of the synthetic experiments should be replicated with human participants, both to achieve concrete results on LLM facilitation, and verify the applicability of synthetic experiments themselves to real world experimentation with humans.